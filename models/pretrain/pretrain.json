{
    "dataset_path": "../../datasets/pretrain/dataset.json",
    "tokenizer_path": "../tokenizer.json",
    "max_length": 1024,
    "model_dim": 1024,
    "num_heads": 16,
    "num_layers": 10,
    "dropout": 0.1,
    "batch_size": 1,
    "val_batch_size": 4,
    "n_batches_per_step": 256,
    "max_learning_rate": 2e-3,
    "min_learning_rate": 1e-6,
    "warmup_steps": 0,
    "total_steps": 100000,
    "validation_interval": 200,
    "checkpoint_file": "",
    "checkpoint_step": 0,
    "log_file": "pretrain.log"
}