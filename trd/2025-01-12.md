# 关键内容总结 2025-01-12

## 一、项目现状与问题
- **项目现状**：SwarmClone项目正在预训练阶段，同时进行各模块整合，下一步计划搜集数据并微调模型。
- **现存问题**
    - **模块稳定性问题**：目前项目中存在模块炸了需重开的情况，且未写检测重连代码，导致端口未及时释放等一系列问题，但这些问题在tts前优先级较低。
    - **alignment信息获取问题**：使用cosy的streaming方式时，先生成所有token再合成，可能拿不到alignment信息，若要获取需改很多代码，工作量大。
    - **实时性与交互性问题**：在实现流式输出时，存在中断机制不完善的问题，如asr的抢话中断机制与tts的配合不够紧密，且目前tts输出是一个一个蹦出来，若直接输出整句话观众会快速阅读完毕，体验欠佳。

## 二、技术实现方案探讨
- **关于alignment信息获取**
    - **方案一**：只给每个句子结束的时间戳，生成一个句子就给前端发一个句子时长同时开始播放。此方案相对简单，不需对现有tts模型做太多改动。
    - **方案二**：前端接受token后先存着，收到tts给出的句子时间戳后开始均匀输出直到一个句子打完，然后等下一个时间戳。同时asr在给出一段文本后自动关闭等待tts给出eos再开始识别，将来的弹幕姬同理。此方案可模拟一个一个蹦的效果，但需要解决时间戳精度和中断机制等问题。
- **关于中断机制完善**
    - **方案**：可以让asr发出信息给tts让tts停下，然后tts立刻停下发出eos让前端也停下。同时考虑新建文件夹，实现tts停下但也已经输出一段的情况处理，以及是否使用playsound的硬件级终止指令等。
- **关于多轮对话数据处理**
    - **方案**：一次输入只放一次对话，空的位置全部pad填充，不同输入之间对模型来说是完全独立的。同一次对话间的好几轮直接连接，利用自回归模型的特性，模型能分清上下文。在输入数据时，可通过两个空行、eos或attn mask等方式标明一轮对话的结束，避免把不同一次对话的数据放一起。

## 三、后续工作计划
- **模型微调任务**：包括指令遵循、说话风格、弹幕回应三方面。指令遵循可用多轮指令数据，说话风格需用多轮对话数据，可能需其他ai生成特定风格对话数据；弹幕回应主要靠提示词。后续需系统学习相关知识，明确qa数据输入输出格式，如输入格式为“Q:XXXXXXXX  A:XXX”，预测结果为“Q:XXX不变 PA:XXXXX”，然后mask掉一样的Q部分，对A和预测的PA部分算损失。
- **技术整合优化**：继续推进对语言大模型、语音模型、虚拟形象、语音输入等的统一调度整合，解决现有实时性、交互性等问题，提升项目整体性能和用户体验。
